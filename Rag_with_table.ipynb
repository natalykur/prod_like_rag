{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMkqthAAa9uIPl1LZLCLgzY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/natalykur/prod_like_rag/blob/main/Rag_with_table.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Complete RAG System for Pandas Data\n",
        "\n",
        "# ===============================================\n",
        "# SECTION 1: INSTALLATION AND SETUP\n",
        "# ===============================================\n",
        "\n",
        "# Install required packages\n",
        "!pip install -q sentence-transformers\n",
        "!pip install -q chromadb\n",
        "!pip install -q openai\n",
        "!pip install -q ragas\n",
        "!pip install -q datasets\n",
        "!pip install -q langchain\n",
        "!pip install -q langchain-openai\n",
        "!pip install -q pandas numpy scikit-learn\n",
        "!pip install -q plotly\n",
        "\n",
        "# Import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import os\n",
        "from typing import List, Dict, Optional\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Vector and embedding libraries\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import chromadb\n",
        "from chromadb.utils import embedding_functions\n",
        "\n",
        "# LLM and RAG libraries\n",
        "import openai\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.schema import Document\n",
        "\n",
        "# Evaluation libraries\n",
        "from ragas import evaluate\n",
        "from ragas.metrics import (\n",
        "    faithfulness,\n",
        "    answer_relevancy,\n",
        "    context_recall,\n",
        "    context_precision,\n",
        "    answer_correctness,\n",
        "    answer_similarity\n",
        ")\n",
        "from datasets import Dataset\n",
        "\n",
        "# Visualization\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "# Utility libraries\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from datetime import datetime\n",
        "import time\n",
        "\n",
        "print(\"All libraries installed and imported successfully!\")\n"
      ],
      "metadata": {
        "id": "Ox7CwXChnKao"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uhYcmAg9i57s"
      },
      "outputs": [],
      "source": [
        "\n",
        "# ===============================================\n",
        "# SECTION 2: CONFIGURATION AND SETUP\n",
        "# ===============================================\n",
        "from google.colab import userdata\n",
        "\n",
        "# Configuration\n",
        "class RAGConfig:\n",
        "    def __init__(self):\n",
        "        self.embedding_model = 'all-MiniLM-L6-v2'\n",
        "        self.chunk_size = 512\n",
        "        self.chunk_overlap = 50\n",
        "        self.top_k_retrieval = 5\n",
        "        self.temperature = 0.3\n",
        "        self.max_tokens = 500\n",
        "\n",
        "\n",
        "        # OpenAI API key (set your key here)\n",
        "        #self.openai_api_key = \"your-openai-api-key-here\"  # Replace with your actual key\n",
        "        # Fetch the API key from Colab secrets\n",
        "        try:\n",
        "            self.openai_api_key = userdata.get('OPENAI_API_KEY')\n",
        "        except userdata.SecretNotFoundError:\n",
        "            print(\"OpenAI API key not found in Colab secrets. Please add it as 'OPENAI_API_KEY'.\")\n",
        "            self.openai_api_key = None # Or raise an error\n",
        "\n",
        "        # Vector database settings\n",
        "        self.collection_name = \"ecommerce_products\"\n",
        "        self.persist_directory = \"/content/chroma_db\"\n",
        "\n",
        "config = RAGConfig()\n",
        "\n",
        "# Set OpenAI API key\n",
        "os.environ[\"OPENAI_API_KEY\"] = config.openai_api_key\n",
        "openai.api_key = config.openai_api_key\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ===============================================\n",
        "# SECTION 3: DATA GENERATION\n",
        "# ===============================================\n",
        "\n",
        "def generate_ecommerce_data(num_records=500):\n",
        "    \"\"\"Generate sample e-commerce dataset\"\"\"\n",
        "    import random\n",
        "\n",
        "    np.random.seed(42)\n",
        "    random.seed(42)\n",
        "\n",
        "    categories = ['Electronics', 'Clothing', 'Home & Garden', 'Books', 'Sports', 'Beauty']\n",
        "\n",
        "    products_by_category = {\n",
        "        'Electronics': ['iPhone 14', 'Samsung Galaxy S23', 'MacBook Pro', 'Dell XPS', 'iPad Air', 'Sony Headphones'],\n",
        "        'Clothing': ['Nike T-Shirt', 'Levis Jeans', 'Adidas Sneakers', 'H&M Dress', 'Zara Jacket', 'Uniqlo Hoodie'],\n",
        "        'Home & Garden': ['Coffee Maker', 'Vacuum Cleaner', 'Garden Hose', 'Dining Table', 'Bed Sheets', 'Plant Pot'],\n",
        "        'Books': ['Python Programming', 'Data Science Handbook', 'Machine Learning', 'Deep Learning', 'Statistics', 'AI Ethics'],\n",
        "        'Sports': ['Yoga Mat', 'Tennis Racket', 'Running Shoes', 'Basketball', 'Dumbbells', 'Bicycle'],\n",
        "        'Beauty': ['Face Cream', 'Shampoo', 'Lipstick', 'Perfume', 'Sunscreen', 'Hair Oil']\n",
        "    }\n",
        "\n",
        "    price_ranges = {\n",
        "        'Electronics': (50, 2000),\n",
        "        'Clothing': (15, 200),\n",
        "        'Home & Garden': (20, 500),\n",
        "        'Books': (10, 60),\n",
        "        'Sports': (25, 300),\n",
        "        'Beauty': (8, 100)\n",
        "    }\n",
        "\n",
        "    data = []\n",
        "\n",
        "    for i in range(num_records):\n",
        "        category = random.choice(categories)\n",
        "        product = random.choice(products_by_category[category])\n",
        "\n",
        "        min_price, max_price = price_ranges[category]\n",
        "        price = round(random.uniform(min_price, max_price), 2)\n",
        "        rating = round(np.random.beta(7, 2) * 5, 1)\n",
        "\n",
        "        base_sales = random.randint(50, 1000)\n",
        "        price_factor = 1 - (price - min_price) / (max_price - min_price) * 0.3\n",
        "        sales = int(base_sales * price_factor)\n",
        "\n",
        "        revenue = price * sales\n",
        "        discount = random.choice([0, 5, 10, 15, 20, 25]) if random.random() < 0.3 else 0\n",
        "        stock_level = random.randint(0, 500)\n",
        "        stock_status = 'Out of Stock' if stock_level == 0 else 'Low Stock' if stock_level < 50 else 'In Stock'\n",
        "\n",
        "        satisfaction = 'High' if rating >= 4.0 else 'Medium' if rating >= 3.0 else 'Low'\n",
        "\n",
        "        data.append({\n",
        "            'product_id': f'P{i+1:04d}',\n",
        "            'product_name': product,\n",
        "            'category': category,\n",
        "            'price': price,\n",
        "            'rating': rating,\n",
        "            'sales_quantity': sales,\n",
        "            'revenue': round(revenue, 2),\n",
        "            'discount_percent': discount,\n",
        "            'stock_level': stock_level,\n",
        "            'stock_status': stock_status,\n",
        "            'customer_satisfaction': satisfaction\n",
        "        })\n",
        "\n",
        "    return pd.DataFrame(data)\n",
        "\n",
        "# Generate the dataset\n",
        "print(\"Generating e-commerce dataset...\")\n",
        "df = generate_ecommerce_data(500)\n",
        "print(f\"Dataset generated with {len(df)} records\")\n",
        "print(\"\\nDataset sample:\")\n",
        "print(df.head())\n",
        "\n",
        "# Save dataset\n",
        "df.to_csv('/content/ecommerce_products.csv', index=False)\n",
        "print(\"\\nDataset saved to /content/ecommerce_products.csv\")\n"
      ],
      "metadata": {
        "id": "SPkQoqlfnWvC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================================\n",
        "# SECTION 4: TEXT PROCESSING AND VECTORIZATION\n",
        "# ===============================================\n",
        "\n",
        "# **Text:** Processing the data and creating vector embeddings.\n",
        "\n",
        "# **Paragraph:** This section defines a `DataProcessor` class responsible for transforming the Pandas DataFrame into text chunks and generating vector embeddings for these chunks. It uses the `SentenceTransformer` library to create embeddings based on the configured model.\n",
        "\n",
        "class DataProcessor:\n",
        "    def __init__(self, config: RAGConfig):\n",
        "        self.config = config\n",
        "        self.embedding_model = SentenceTransformer(config.embedding_model)\n",
        "\n",
        "    def create_document_chunks(self, df: pd.DataFrame) -> List[Dict]:\n",
        "        \"\"\"Convert DataFrame rows to text chunks for vectorization\"\"\"\n",
        "        chunks = []\n",
        "\n",
        "        for idx, row in df.iterrows():\n",
        "            # Create comprehensive text representation\n",
        "            text = f\"Product: {row['product_name']}\\n\"\n",
        "            text += f\"Category: {row['category']}\\n\"\n",
        "            text += f\"Price: ${row['price']}\\n\"\n",
        "            text += f\"Rating: {row['rating']}/5\\n\"\n",
        "            text += f\"Sales Quantity: {row['sales_quantity']} units\\n\"\n",
        "            text += f\"Revenue: ${row['revenue']:,.2f}\\n\"\n",
        "            text += f\"Discount: {row['discount_percent']}%\\n\"\n",
        "            text += f\"Stock Level: {row['stock_level']} units\\n\"\n",
        "            text += f\"Stock Status: {row['stock_status']}\\n\"\n",
        "            text += f\"Customer Satisfaction: {row['customer_satisfaction']}\\n\"\n",
        "\n",
        "            # Add contextual information\n",
        "            text += f\"\\nThis is a {row['category'].lower()} product with \"\n",
        "            text += f\"{'high' if row['rating'] >= 4.0 else 'medium' if row['rating'] >= 3.0 else 'low'} customer rating. \"\n",
        "\n",
        "            if row['discount_percent'] > 0:\n",
        "                text += f\"Currently on sale with {row['discount_percent']}% discount. \"\n",
        "\n",
        "            text += f\"Stock status is {row['stock_status'].lower()}.\"\n",
        "\n",
        "            chunks.append({\n",
        "                'id': row['product_id'],\n",
        "                'text': text,\n",
        "                'metadata': {\n",
        "                    'product_id': row['product_id'],\n",
        "                    'product_name': row['product_name'],\n",
        "                    'category': row['category'],\n",
        "                    'price': row['price'],\n",
        "                    'rating': row['rating'],\n",
        "                    'sales_quantity': row['sales_quantity'],\n",
        "                    'revenue': row['revenue'],\n",
        "                    'stock_status': row['stock_status']\n",
        "                }\n",
        "            })\n",
        "\n",
        "        return chunks\n",
        "\n",
        "    def create_embeddings(self, chunks: List[Dict]) -> List[np.ndarray]:\n",
        "        \"\"\"Create embeddings for text chunks\"\"\"\n",
        "        texts = [chunk['text'] for chunk in chunks]\n",
        "        embeddings = self.embedding_model.encode(texts, show_progress_bar=True)\n",
        "        return embeddings\n",
        "\n",
        "# Initialize processor\n",
        "processor = DataProcessor(config)\n",
        "\n",
        "# Create chunks and embeddings\n",
        "print(\"Processing data into chunks...\")\n",
        "chunks = processor.create_document_chunks(df)\n",
        "print(f\"Created {len(chunks)} chunks\")\n",
        "\n",
        "print(\"\\nSample chunk:\")\n",
        "print(chunks[0]['text'][:300] + \"...\")\n",
        "\n",
        "print(\"\\nCreating embeddings...\")\n",
        "embeddings = processor.create_embeddings(chunks)\n",
        "print(f\"Created embeddings with shape: {embeddings.shape}\")"
      ],
      "metadata": {
        "id": "nDUYG1KQoETa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================================\n",
        "# SECTION 5: VECTOR DATABASE SETUP\n",
        "# ===============================================\n",
        "\n",
        "# **Text:** Setting up the vector database.\n",
        "\n",
        "# **Paragraph:** This section configures and initializes a ChromaDB vector database to store the embeddings of the product information. It defines a `VectorDatabase` class that handles the creation of a collection, adding documents (chunks and metadata), and searching for relevant information based on a query.\n",
        "\n",
        "class VectorDatabase:\n",
        "    def __init__(self, config: RAGConfig):\n",
        "        self.config = config\n",
        "        self.client = chromadb.PersistentClient(path=config.persist_directory)\n",
        "        self.embedding_function = embedding_functions.SentenceTransformerEmbeddingFunction(\n",
        "            model_name=config.embedding_model\n",
        "        )\n",
        "        self.collection = None\n",
        "\n",
        "    def create_collection(self, chunks: List[Dict]):\n",
        "        \"\"\"Create and populate vector database collection\"\"\"\n",
        "        try:\n",
        "            # Delete existing collection if it exists\n",
        "            self.client.delete_collection(name=self.config.collection_name)\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "        # Create new collection\n",
        "        self.collection = self.client.create_collection(\n",
        "            name=self.config.collection_name,\n",
        "            embedding_function=self.embedding_function\n",
        "        )\n",
        "\n",
        "        # Add documents to collection\n",
        "        ids = [chunk['id'] for chunk in chunks]\n",
        "        documents = [chunk['text'] for chunk in chunks]\n",
        "        metadatas = [chunk['metadata'] for chunk in chunks]\n",
        "\n",
        "        self.collection.add(\n",
        "            ids=ids,\n",
        "            documents=documents,\n",
        "            metadatas=metadatas\n",
        "        )\n",
        "\n",
        "        print(f\"Added {len(chunks)} documents to vector database\")\n",
        "\n",
        "    def search(self, query: str, top_k: int = 5) -> Dict:\n",
        "        \"\"\"Search for relevant documents\"\"\"\n",
        "        if not self.collection:\n",
        "            self.collection = self.client.get_collection(name=self.config.collection_name)\n",
        "\n",
        "        results = self.collection.query(\n",
        "            query_texts=[query],\n",
        "            n_results=top_k\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            'documents': results['documents'][0],\n",
        "            'metadatas': results['metadatas'][0],\n",
        "            'distances': results['distances'][0],\n",
        "            'ids': results['ids'][0]\n",
        "        }\n",
        "\n",
        "# Initialize vector database\n",
        "print(\"Setting up vector database...\")\n",
        "vector_db = VectorDatabase(config)\n",
        "vector_db.create_collection(chunks)\n",
        "print(\"Vector database setup complete!\")\n",
        "\n",
        "# Test search\n",
        "test_query = \"What are the highest rated electronics?\"\n",
        "search_results = vector_db.search(test_query, top_k=3)\n",
        "print(f\"\\nTest search for: '{test_query}'\")\n",
        "print(f\"Found {len(search_results['documents'])} relevant documents\")"
      ],
      "metadata": {
        "id": "DsTnYiekn3du"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================================\n",
        "# SECTION 6: RAG SYSTEM IMPLEMENTATION\n",
        "# ===============================================\n",
        "\n",
        "# **Text:** Implementing the Retrieval-Augmented Generation (RAG) system.\n",
        "\n",
        "# **Paragraph:** This section defines the core `RAGSystem` class. It integrates the vector database for retrieval and a language model (GPT-3.5-turbo) for generating answers. The system takes a user query, retrieves relevant product information from the vector database, and then uses the LLM to generate a comprehensive answer based on the retrieved context.\n",
        "\n",
        "class RAGSystem:\n",
        "    def __init__(self, config: RAGConfig, vector_db: VectorDatabase):\n",
        "        self.config = config\n",
        "        self.vector_db = vector_db\n",
        "        self.llm = ChatOpenAI(\n",
        "            model_name=\"gpt-3.5-turbo\",\n",
        "            temperature=config.temperature,\n",
        "            max_tokens=config.max_tokens\n",
        "        )\n",
        "\n",
        "    def retrieve(self, query: str) -> List[str]:\n",
        "        \"\"\"Retrieve relevant documents for a query\"\"\"\n",
        "        search_results = self.vector_db.search(query, top_k=self.config.top_k_retrieval)\n",
        "        return search_results['documents']\n",
        "\n",
        "    def generate_answer(self, query: str, contexts: List[str]) -> str:\n",
        "        \"\"\"Generate answer using LLM with retrieved contexts\"\"\"\n",
        "        context_text = \"\\n\\n\".join([f\"Context {i+1}:\\n{ctx}\" for i, ctx in enumerate(contexts)])\n",
        "\n",
        "        prompt = f\"\"\"Based on the following product information, please answer the user's question accurately and comprehensively.\n",
        "\n",
        "Product Information:\n",
        "{context_text}\n",
        "\n",
        "Question: {query}\n",
        "\n",
        "Instructions:\n",
        "- Use only the information provided in the contexts\n",
        "- Be specific and include relevant details (prices, ratings, quantities, etc.)\n",
        "- If the information is not available in the contexts, clearly state that\n",
        "- Format your response clearly and concisely\n",
        "\n",
        "Answer:\"\"\"\n",
        "\n",
        "        try:\n",
        "            response = self.llm.predict(prompt)\n",
        "            return response.strip()\n",
        "        except Exception as e:\n",
        "            return f\"Error generating response: {str(e)}\"\n",
        "\n",
        "    def query(self, question: str) -> Dict:\n",
        "        \"\"\"Complete RAG pipeline: retrieve + generate\"\"\"\n",
        "        start_time = time.time()\n",
        "\n",
        "        # Retrieve relevant contexts\n",
        "        contexts = self.retrieve(question)\n",
        "\n",
        "        # Generate answer\n",
        "        answer = self.generate_answer(question, contexts)\n",
        "\n",
        "        end_time = time.time()\n",
        "\n",
        "        return {\n",
        "            'question': question,\n",
        "            'answer': answer,\n",
        "            'contexts': contexts,\n",
        "            'response_time': end_time - start_time\n",
        "        }\n",
        "\n",
        "# Initialize RAG system\n",
        "print(\"Initializing RAG system...\")\n",
        "rag_system = RAGSystem(config, vector_db)\n",
        "print(\"RAG system ready!\")"
      ],
      "metadata": {
        "id": "47YKSa2qoIL9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================================\n",
        "# SECTION 7: TESTING THE RAG SYSTEM\n",
        "# ===============================================\n",
        "\n",
        "# **Text:** Testing the RAG system with sample queries.\n",
        "\n",
        "# **Paragraph:** This section provides a set of test questions to evaluate the performance of the RAG system. It iterates through these questions, queries the system, and prints the generated answer and the response time for each question. This helps in quickly verifying if the system is working as expected.\n",
        "\n",
        "# Test queries\n",
        "test_questions = [\n",
        "    \"What is the most expensive product?\",\n",
        "    \"Which products have the highest rating?\",\n",
        "    \"What electronics are currently in stock?\",\n",
        "    \"Which category has the best customer satisfaction?\",\n",
        "    \"What products have discounts available?\",\n",
        "    \"Show me products with low stock levels\",\n",
        "    \"What is the average price of clothing items?\",\n",
        "    \"Which products generated the most revenue?\"\n",
        "]\n",
        "\n",
        "print(\"Testing RAG system with sample questions...\\n\")\n",
        "\n",
        "test_results = []\n",
        "for question in test_questions[:4]:  # Test first 4 questions\n",
        "    print(f\"Question: {question}\")\n",
        "    result = rag_system.query(question)\n",
        "    print(f\"Answer: {result['answer']}\")\n",
        "    print(f\"Response time: {result['response_time']:.2f} seconds\")\n",
        "    print(\"-\" * 80)\n",
        "    test_results.append(result)"
      ],
      "metadata": {
        "id": "ji7hzVwPoM0K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================================\n",
        "# SECTION 8: EVALUATION DATASET GENERATION\n",
        "# ===============================================\n",
        "\n",
        "# **Text:** Generating an evaluation dataset for RAGAS.\n",
        "\n",
        "# **Paragraph:** This section defines a function `generate_evaluation_dataset` to create a dataset specifically for evaluating the RAG system using the RAGAS framework. It generates questions based on templates and extracts the corresponding ground truth answers from the original DataFrame. This dataset will be used to assess the quality of the RAG system's responses.\n",
        "\n",
        "def generate_evaluation_dataset(df: pd.DataFrame, num_questions: int = 30) -> List[Dict]:\n",
        "    \"\"\"Generate evaluation dataset for RAGAS\"\"\"\n",
        "    import random\n",
        "\n",
        "    evaluation_data = []\n",
        "\n",
        "    # Question templates with expected answers\n",
        "    templates = [\n",
        "        {\n",
        "            \"template\": \"What is the price of {product}?\",\n",
        "            \"type\": \"price_query\",\n",
        "            \"answer_func\": lambda row: f\"The price of {row['product_name']} is ${row['price']}.\"\n",
        "        },\n",
        "        {\n",
        "            \"template\": \"What is the rating of {product}?\",\n",
        "            \"type\": \"rating_query\",\n",
        "            \"answer_func\": lambda row: f\"The rating of {row['product_name']} is {row['rating']} out of 5.\"\n",
        "        },\n",
        "        {\n",
        "            \"template\": \"How many units of {product} were sold?\",\n",
        "            \"type\": \"sales_query\",\n",
        "            \"answer_func\": lambda row: f\"{row['product_name']} sold {row['sales_quantity']} units.\"\n",
        "        },\n",
        "        {\n",
        "            \"template\": \"What category does {product} belong to?\",\n",
        "            \"type\": \"category_query\",\n",
        "            \"answer_func\": lambda row: f\"{row['product_name']} belongs to the {row['category']} category.\"\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    # Generate questions\n",
        "    products = df['product_name'].unique()\n",
        "\n",
        "    for i in range(num_questions):\n",
        "        template_info = random.choice(templates)\n",
        "        product = random.choice(products)\n",
        "\n",
        "        question = template_info[\"template\"].format(product=product)\n",
        "\n",
        "        # Get product info\n",
        "        product_row = df[df['product_name'] == product].iloc[0]\n",
        "        ground_truth = template_info[\"answer_func\"](product_row)\n",
        "\n",
        "        # Get relevant context\n",
        "        context = f\"Product: {product_row['product_name']}, Price: ${product_row['price']}, \"\n",
        "        context += f\"Rating: {product_row['rating']}, Sales: {product_row['sales_quantity']}, \"\n",
        "        context += f\"Category: {product_row['category']}\"\n",
        "\n",
        "        evaluation_data.append({\n",
        "            'question': question,\n",
        "            'ground_truth': ground_truth,\n",
        "            'contexts': [context],\n",
        "            'answer': ground_truth  # Will be replaced with RAG answer during evaluation\n",
        "        })\n",
        "\n",
        "    return evaluation_data\n",
        "\n",
        "# Generate evaluation dataset\n",
        "print(\"Generating evaluation dataset...\")\n",
        "eval_data = generate_evaluation_dataset(df, num_questions=20)\n",
        "print(f\"Generated {len(eval_data)} evaluation questions\")\n",
        "\n",
        "# Show sample evaluation data\n",
        "print(\"\\nSample evaluation questions:\")\n",
        "for i, item in enumerate(eval_data[:3]):\n",
        "    print(f\"{i+1}. Question: {item['question']}\")\n",
        "    print(f\"    Ground Truth: {item['ground_truth']}\")\n",
        "    print()"
      ],
      "metadata": {
        "id": "29WhnY9ooYdt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================================\n",
        "# SECTION 9: RAG EVALUATION WITH RAGAS\n",
        "# ===============================================\n",
        "\n",
        "# **Text:** Evaluating the RAG system using RAGAS.\n",
        "\n",
        "# **Paragraph:** This section defines a function `evaluate_rag_system` that takes the RAG system and the evaluation dataset as input and uses the RAGAS framework to assess its performance. It generates answers for the evaluation questions using the RAG system and then calculates several metrics such as context precision, context recall, faithfulness, answer relevancy, and answer correctness.\n",
        "\n",
        "def evaluate_rag_system(rag_system: RAGSystem, eval_data: List[Dict]) -> Dict:\n",
        "    \"\"\"Evaluate RAG system using RAGAS metrics\"\"\"\n",
        "\n",
        "    # Generate answers using RAG system\n",
        "    print(\"Generating answers for evaluation...\")\n",
        "    for item in eval_data:\n",
        "        rag_result = rag_system.query(item['question'])\n",
        "        item['answer'] = rag_result['answer']\n",
        "        item['contexts'] = rag_result['contexts']\n",
        "\n",
        "    # Convert to RAGAS format\n",
        "    dataset_dict = {\n",
        "        'question': [item['question'] for item in eval_data],\n",
        "        'answer': [item['answer'] for item in eval_data],\n",
        "        'contexts': [item['contexts'] for item in eval_data],\n",
        "        'ground_truth': [item['ground_truth'] for item in eval_data]\n",
        "    }\n",
        "\n",
        "    dataset = Dataset.from_dict(dataset_dict)\n",
        "\n",
        "    # Run evaluation\n",
        "    print(\"Running RAGAS evaluation...\")\n",
        "    try:\n",
        "        result = evaluate(\n",
        "            dataset,\n",
        "            metrics=[\n",
        "                context_precision,\n",
        "                context_recall,\n",
        "                faithfulness,\n",
        "                answer_relevancy,\n",
        "                answer_correctness\n",
        "            ],\n",
        "        )\n",
        "        return result\n",
        "    except Exception as e:\n",
        "        print(f\"Evaluation error: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "# Note: Uncomment below to run evaluation (requires valid OpenAI API key)\n",
        "eval_results = evaluate_rag_system(rag_system, eval_data[:10])  # Evaluate first 10 questions\n",
        "if eval_results:\n",
        "     print(\"Evaluation Results:\")\n",
        "     for metric, score in eval_results.items():\n",
        "         print(f\"{metric}: {score:.4f}\")"
      ],
      "metadata": {
        "id": "8918GI6LoYlF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================================\n",
        "# SECTION 10: VISUALIZATION AND ANALYTICS\n",
        "# ===============================================\n",
        "\n",
        "# **Text:** Creating a visualization dashboard for the RAG system.\n",
        "\n",
        "# **Paragraph:** This section defines a function `create_rag_analytics_dashboard` that generates an interactive dashboard using Plotly. The dashboard provides an overview of the e-commerce dataset through various plots such as product distribution by category, price distribution, rating distribution, and revenue by category. It also visualizes the response times of the RAG system for the test queries.\n",
        "\n",
        "def create_rag_analytics_dashboard(df: pd.DataFrame, test_results: List[Dict]):\n",
        "    \"\"\"Create analytics dashboard for RAG system performance\"\"\"\n",
        "\n",
        "    # Dataset overview\n",
        "    fig1 = make_subplots(\n",
        "        rows=2, cols=2,\n",
        "        subplot_titles=('Products by Category', 'Price Distribution',\n",
        "                        'Rating Distribution', 'Revenue by Category'),\n",
        "        specs=[[{'type': 'domain'}, {'type': 'histogram'}],\n",
        "               [{'type': 'histogram'}, {'type': 'bar'}]]\n",
        "    )\n",
        "\n",
        "    # Products by category (pie chart)\n",
        "    category_counts = df['category'].value_counts()\n",
        "    fig1.add_trace(\n",
        "        go.Pie(labels=category_counts.index, values=category_counts.values, name=\"Products\"),\n",
        "        row=1, col=1\n",
        "    )\n",
        "\n",
        "    # Price distribution\n",
        "    fig1.add_trace(\n",
        "        go.Histogram(x=df['price'], name=\"Price\", nbinsx=30),\n",
        "        row=1, col=2\n",
        "    )\n",
        "\n",
        "    # Rating distribution\n",
        "    fig1.add_trace(\n",
        "        go.Histogram(x=df['rating'], name=\"Rating\", nbinsx=20),\n",
        "        row=2, col=1\n",
        "    )\n",
        "\n",
        "    # Revenue by category\n",
        "    revenue_by_category = df.groupby('category')['revenue'].sum().sort_values(ascending=True)\n",
        "    fig1.add_trace(\n",
        "        go.Bar(x=revenue_by_category.values, y=revenue_by_category.index,\n",
        "                orientation='h', name=\"Revenue\"),\n",
        "        row=2, col=2\n",
        "    )\n",
        "\n",
        "    fig1.update_layout(height=800, title_text=\"E-commerce Dataset Overview\")\n",
        "    fig1.show()\n",
        "\n",
        "    # RAG Performance metrics\n",
        "    if test_results:\n",
        "        response_times = [result['response_time'] for result in test_results]\n",
        "        questions = [result['question'][:50] + \"...\" if len(result['question']) > 50\n",
        "                     else result['question'] for result in test_results]\n",
        "\n",
        "        fig2 = go.Figure()\n",
        "        fig2.add_trace(go.Bar(\n",
        "            x=questions,\n",
        "            y=response_times,\n",
        "            name='Response Time (seconds)',\n",
        "            text=[f\"{t:.2f}s\" for t in response_times],\n",
        "            textposition='auto'\n",
        "        ))\n",
        "\n",
        "        fig2.update_layout(\n",
        "            title=\"RAG System Response Times\",\n",
        "            xaxis_title=\"Questions\",\n",
        "            yaxis_title=\"Response Time (seconds)\",\n",
        "            xaxis_tickangle=-45,\n",
        "            height=500\n",
        "        )\n",
        "        fig2.show()\n",
        "\n",
        "# Create dashboard\n",
        "print(\"Creating analytics dashboard...\")\n",
        "create_rag_analytics_dashboard(df, test_results)"
      ],
      "metadata": {
        "id": "5ne1SFNFogcI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================================\n",
        "# SECTION 11: ADVANCED RAG FEATURES\n",
        "# ===============================================\n",
        "\n",
        "# **Text:** Implementing advanced features for the RAG system.\n",
        "\n",
        "# **Paragraph:** This section extends the basic `RAGSystem` with an `AdvancedRAGSystem` class. It introduces features like querying with metadata filters (e.g., by category or price range) and tracking query history to provide basic analytics on the system's usage. Note that the filtering is currently implemented at the application level and would ideally be handled by the vector database for efficiency.\n",
        "\n",
        "class AdvancedRAGSystem(RAGSystem):\n",
        "    \"\"\"Enhanced RAG system with additional features\"\"\"\n",
        "\n",
        "    def __init__(self, config: RAGConfig, vector_db: VectorDatabase):\n",
        "        super().__init__(config, vector_db)\n",
        "        self.query_history = []\n",
        "\n",
        "    def query_with_filter(self, question: str, category_filter: str = None,\n",
        "                                price_range: tuple = None) -> Dict:\n",
        "        \"\"\"Query with metadata filtering\"\"\"\n",
        "        # This would require enhanced vector DB implementation\n",
        "        # For now, we'll demonstrate the concept\n",
        "        basic_result = self.query(question)\n",
        "\n",
        "        if category_filter or price_range:\n",
        "            # Filter contexts based on metadata\n",
        "            filtered_contexts = []\n",
        "            for context in basic_result['contexts']:\n",
        "                # Simple filtering logic (in practice, this should be done at vector DB level)\n",
        "                if category_filter and category_filter.lower() in context.lower():\n",
        "                    filtered_contexts.append(context)\n",
        "                elif not category_filter:\n",
        "                    filtered_contexts.append(context)\n",
        "\n",
        "            if filtered_contexts:\n",
        "                basic_result['contexts'] = filtered_contexts\n",
        "                basic_result['answer'] = self.generate_answer(question, filtered_contexts)\n",
        "\n",
        "        self.query_history.append(basic_result)\n",
        "        return basic_result\n",
        "\n",
        "    def get_query_analytics(self) -> Dict:\n",
        "        \"\"\"Get analytics on query history\"\"\"\n",
        "        if not self.query_history:\n",
        "            return {}\n",
        "\n",
        "        total_queries = len(self.query_history)\n",
        "        avg_response_time = np.mean([q['response_time'] for q in self.query_history])\n",
        "\n",
        "        return {\n",
        "            'total_queries': total_queries,\n",
        "            'average_response_time': avg_response_time,\n",
        "            'recent_queries': [q['question'] for q in self.query_history[-5:]]\n",
        "        }\n",
        "\n",
        "# Initialize advanced RAG system\n",
        "advanced_rag = AdvancedRAGSystem(config, vector_db)\n",
        "\n",
        "# Test advanced features\n",
        "print(\"Testing advanced RAG features...\")\n",
        "filtered_result = advanced_rag.query_with_filter(\n",
        "    \"What are the best electronics?\",\n",
        "    category_filter=\"Electronics\"\n",
        ")\n",
        "print(f\"Filtered query result: {filtered_result['answer'][:200]}...\")"
      ],
      "metadata": {
        "id": "SUH3gEsJo1GP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================================\n",
        "# SECTION 12: INTERACTIVE DEMO\n",
        "# ===============================================\n",
        "\n",
        "# **Text:** Running an interactive demo of the RAG system.\n",
        "\n",
        "# **Paragraph:** This section provides an interactive command-line interface to test the RAG system with custom questions. Users can type in their questions about the e-commerce dataset, and the system will retrieve relevant information and generate an answer. The demo continues until the user types 'quit'. It also offers an option to display the retrieved contexts.\n",
        "\n",
        "def interactive_rag_demo():\n",
        "    \"\"\"Interactive demo function for testing RAG system\"\"\"\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"INTERACTIVE RAG SYSTEM DEMO\")\n",
        "    print(\"=\"*60)\n",
        "    print(\"You can ask questions about the e-commerce dataset.\")\n",
        "    print(\"Example questions:\")\n",
        "    print(\"- What is the most expensive product?\")\n",
        "    print(\"- Which electronics have high ratings?\")\n",
        "    print(\"- Show me products with discounts\")\n",
        "    print(\"- What's the average price in each category?\")\n",
        "    print(\"\\nType 'quit' to exit the demo.\")\n",
        "    print(\"-\"*60)\n",
        "\n",
        "    while True:\n",
        "        user_question = input(\"\\nYour question: \").strip()\n",
        "\n",
        "        if user_question.lower() in ['quit', 'exit', 'q']:\n",
        "            print(\"Demo ended. Thank you!\")\n",
        "            break\n",
        "\n",
        "        if not user_question:\n",
        "            print(\"Please enter a question.\")\n",
        "            continue\n",
        "\n",
        "        print(\"\\nProcessing your question...\")\n",
        "        result = rag_system.query(user_question)\n",
        "\n",
        "        print(f\"\\nAnswer: {result['answer']}\")\n",
        "        print(f\"Response time: {result['response_time']:.2f} seconds\")\n",
        "\n",
        "        # Show relevant contexts (optional)\n",
        "        show_contexts = input(\"\\nShow relevant contexts? (y/n): \").strip().lower()\n",
        "        if show_contexts == 'y':\n",
        "            print(\"\\nRelevant contexts:\")\n",
        "            for i, context in enumerate(result['contexts'][:2], 1):\n",
        "                print(f\"\\nContext {i}:\")\n",
        "                print(context[:300] + \"...\" if len(context) > 300 else context)\n",
        "\n",
        "# Uncomment to run interactive demo\n",
        "interactive_rag_demo()"
      ],
      "metadata": {
        "id": "fDkfjetBpNwX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================================\n",
        "# SECTION 13: SAVING AND LOADING MODELS\n",
        "# ===============================================\n",
        "\n",
        "# **Text:** Saving and loading the RAG system components.\n",
        "\n",
        "# **Paragraph:** This section implements functionality to save the trained RAG system (specifically the metadata and implicitly the persisted vector database) to a specified path. It also includes a function to load the saved RAG system components, allowing for the system to be reused without retraining and rebuilding the vector database.\n",
        "\n",
        "def save_rag_system(rag_system: RAGSystem, vector_db: VectorDatabase, save_path: str):\n",
        "    \"\"\"Save RAG system components\"\"\"\n",
        "    import pickle\n",
        "\n",
        "    # Save metadata\n",
        "    metadata = {\n",
        "        'config': config.__dict__,\n",
        "        'num_documents': len(chunks),\n",
        "        'embedding_model': config.embedding_model,\n",
        "        'created_at': datetime.now().isoformat()\n",
        "    }\n",
        "\n",
        "    with open(f\"{save_path}/metadata.json\", 'w') as f:\n",
        "        json.dump(metadata, f, indent=2)\n",
        "\n",
        "    # Vector database is already persisted\n",
        "    print(f\"RAG system saved to {save_path}\")\n",
        "\n",
        "def load_rag_system(save_path: str) -> tuple:\n",
        "    \"\"\"Load RAG system components\"\"\"\n",
        "    # Load metadata\n",
        "    with open(f\"{save_path}/metadata.json\", 'r') as f:\n",
        "        metadata = json.load(f)\n",
        "\n",
        "    # Recreate components\n",
        "    loaded_config = RAGConfig()\n",
        "    loaded_vector_db = VectorDatabase(loaded_config)\n",
        "    loaded_rag_system = RAGSystem(loaded_config, loaded_vector_db)\n",
        "\n",
        "    print(f\"RAG system loaded from {save_path}\")\n",
        "    return loaded_rag_system, loaded_vector_db, metadata\n",
        "\n",
        "# Save the current system\n",
        "save_path = \"/content/rag_system\"\n",
        "os.makedirs(save_path, exist_ok=True)\n",
        "save_rag_system(rag_system, vector_db, save_path)"
      ],
      "metadata": {
        "id": "L9R_HWlJp4qT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================================\n",
        "# SECTION 14: SUMMARY AND NEXT STEPS\n",
        "# ===============================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"RAG SYSTEM SETUP COMPLETE!\")\n",
        "print(\"=\"*80)\n",
        "print(f\"✅ Generated dataset with {len(df)} products\")\n",
        "print(f\"✅ Created {len(chunks)} text chunks\")\n",
        "print(f\"✅ Built vector database with embeddings\")\n",
        "print(f\"✅ Implemented complete RAG pipeline\")\n",
        "print(f\"✅ Tested system with sample queries\")\n",
        "print(f\"✅ Created evaluation framework\")\n",
        "print(f\"✅ Generated analytics dashboard\")\n",
        "\n",
        "print(\"\\nSystem Components:\")\n",
        "print(f\"- Embedding Model: {config.embedding_model}\")\n",
        "print(f\"- Vector Database: ChromaDB\")\n",
        "print(f\"- LLM: GPT-3.5-turbo\")\n",
        "print(f\"- Top-K Retrieval: {config.top_k_retrieval}\")\n",
        "\n",
        "print(\"\\nNext Steps:\")\n",
        "print(\"1. Set your OpenAI API key in the config\")\n",
        "print(\"2. Run the interactive demo to test queries\")\n",
        "print(\"3. Evaluate system performance with RAGAS\")\n",
        "print(\"4. Customize for your specific dataset\")\n",
        "print(\"5. Deploy to production environment\")\n",
        "\n",
        "print(\"\\nFiles Created:\")\n",
        "print(\"- /content/ecommerce_products.csv\")\n",
        "print(\"- /content/chroma_db/ (vector database)\")\n",
        "print(\"- /content/rag_system/ (saved model)\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        ""
      ],
      "metadata": {
        "id": "btJnb43uqMMr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}